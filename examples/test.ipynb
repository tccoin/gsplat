{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parser] 1 images.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from datasets.rgbd import Parser, Dataset\n",
    "\n",
    "data_dir = '/run/media/junzhe/SLAM_DATA/data/museum/kitchen_rgbd_pcd/'\n",
    "data_factor = 1\n",
    "\n",
    "parser = Parser(\n",
    "    data_dir=data_dir,\n",
    "    factor=data_factor,\n",
    "    normalize=True,\n",
    "    test_every=10,\n",
    ")\n",
    "\n",
    "\n",
    "dataset = Dataset(parser, split=\"train\", load_depths=True)\n",
    "np.arange(len(parser.image_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parser] 307 images.\n",
      "Scene scale: 0.7858290874306474\n",
      "Model initialized. Number of GS: 99790\n",
      "/home/junzhe/miniconda3/envs/gs/lib/python3.10/site-packages/torchmetrics/functional/image/lpips.py:325: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(model_path, map_location=\"cpu\"), strict=False)\n",
      "╭─────────────── \u001b[1mviser\u001b[0m ───────────────╮\n",
      "│             ╷                       │\n",
      "│   HTTP      │ http://0.0.0.0:8080   │\n",
      "│   Websocket │ ws://0.0.0.0:8080     │\n",
      "│             ╵                       │\n",
      "╰─────────────────────────────────────╯\n",
      "  0%|                                                 | 0/30000 [00:00<?, ?it/s]/home/junzhe/miniconda3/envs/gs/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "loss=0.190| sh degree=0| :   2%|▏           | 600/30000 [00:20<10:15, 47.79it/s]Step 600: 0 GSs duplicated, 780 GSs split. Now having 100570 GSs.\n",
      "Step 600: 17960 GSs pruned. Now having 82610 GSs.\n",
      "loss=0.235| sh degree=0| :   2%|▎           | 700/30000 [00:24<29:33, 16.52it/s]Step 700: 0 GSs duplicated, 1457 GSs split. Now having 84067 GSs.\n",
      "Step 700: 1516 GSs pruned. Now having 82551 GSs.\n",
      "loss=0.193| sh degree=0| :   3%|▎           | 799/30000 [00:28<10:40, 45.58it/s]Step 800: 0 GSs duplicated, 1755 GSs split. Now having 84306 GSs.\n",
      "Step 800: 1199 GSs pruned. Now having 83107 GSs.\n",
      "loss=0.202| sh degree=0| :   3%|▎           | 895/30000 [00:34<57:48,  8.39it/s]Step 900: 31 GSs duplicated, 2245 GSs split. Now having 85383 GSs.\n",
      "Step 900: 906 GSs pruned. Now having 84477 GSs.\n",
      "loss=0.190| sh degree=1| :   3%|▍           | 997/30000 [00:38<15:06, 31.98it/s]Step 1000: 137 GSs duplicated, 2744 GSs split. Now having 87358 GSs.\n",
      "Step 1000: 939 GSs pruned. Now having 86419 GSs.\n",
      "loss=0.154| sh degree=1| :   4%|▎        | 1094/30000 [00:45<1:01:57,  7.78it/s]Step 1100: 347 GSs duplicated, 3101 GSs split. Now having 89867 GSs.\n",
      "Step 1100: 1027 GSs pruned. Now having 88840 GSs.\n",
      "loss=0.154| sh degree=1| :   4%|▍          | 1197/30000 [00:51<21:12, 22.64it/s]Step 1200: 703 GSs duplicated, 3223 GSs split. Now having 92766 GSs.\n",
      "Step 1200: 929 GSs pruned. Now having 91837 GSs.\n",
      "loss=0.194| sh degree=1| :   4%|▍          | 1299/30000 [01:03<40:14, 11.89it/s]Step 1300: 992 GSs duplicated, 3395 GSs split. Now having 96224 GSs.\n",
      "Step 1300: 786 GSs pruned. Now having 95438 GSs.\n",
      "loss=0.185| sh degree=1| :   5%|▌          | 1400/30000 [01:05<10:31, 45.28it/s]Step 1400: 1273 GSs duplicated, 3565 GSs split. Now having 100276 GSs.\n",
      "Step 1400: 802 GSs pruned. Now having 99474 GSs.\n",
      "loss=0.151| sh degree=1| :   5%|▌          | 1500/30000 [01:07<09:43, 48.85it/s]Step 1500: 1428 GSs duplicated, 3633 GSs split. Now having 104535 GSs.\n",
      "Step 1500: 776 GSs pruned. Now having 103759 GSs.\n",
      "loss=0.183| sh degree=1| :   5%|▌          | 1598/30000 [01:09<09:44, 48.58it/s]Step 1600: 1731 GSs duplicated, 3779 GSs split. Now having 109269 GSs.\n",
      "Step 1600: 1032 GSs pruned. Now having 108237 GSs.\n",
      "loss=0.171| sh degree=1| :   6%|▌          | 1697/30000 [01:11<10:54, 43.26it/s]Step 1700: 1812 GSs duplicated, 3837 GSs split. Now having 113886 GSs.\n",
      "Step 1700: 813 GSs pruned. Now having 113073 GSs.\n",
      "loss=0.174| sh degree=1| :   6%|▋          | 1798/30000 [01:14<16:34, 28.36it/s]Step 1800: 2036 GSs duplicated, 3922 GSs split. Now having 119031 GSs.\n",
      "Step 1800: 615 GSs pruned. Now having 118416 GSs.\n",
      "loss=0.155| sh degree=1| :   6%|▋          | 1896/30000 [01:17<14:48, 31.62it/s]Step 1900: 2161 GSs duplicated, 3932 GSs split. Now having 124509 GSs.\n",
      "Step 1900: 557 GSs pruned. Now having 123952 GSs.\n",
      "loss=0.182| sh degree=2| :   7%|▋          | 1996/30000 [01:21<09:41, 48.14it/s]Step 2000: 2357 GSs duplicated, 4124 GSs split. Now having 130433 GSs.\n",
      "Step 2000: 464 GSs pruned. Now having 129969 GSs.\n",
      "loss=0.169| sh degree=2| :   7%|▊          | 2097/30000 [01:23<12:33, 37.01it/s]Step 2100: 2405 GSs duplicated, 3981 GSs split. Now having 136355 GSs.\n",
      "Step 2100: 530 GSs pruned. Now having 135825 GSs.\n",
      "loss=0.146| sh degree=2| :   7%|▊          | 2197/30000 [01:26<16:48, 27.58it/s]Step 2200: 2773 GSs duplicated, 4070 GSs split. Now having 142668 GSs.\n",
      "Step 2200: 553 GSs pruned. Now having 142115 GSs.\n",
      "loss=0.151| sh degree=2| :   8%|▊          | 2298/30000 [01:30<16:48, 27.46it/s]Step 2300: 2856 GSs duplicated, 3945 GSs split. Now having 148916 GSs.\n",
      "Step 2300: 580 GSs pruned. Now having 148336 GSs.\n",
      "loss=0.155| sh degree=2| :   8%|▉          | 2398/30000 [01:34<12:07, 37.93it/s]Step 2400: 2886 GSs duplicated, 3717 GSs split. Now having 154939 GSs.\n",
      "Step 2400: 582 GSs pruned. Now having 154357 GSs.\n",
      "loss=0.151| sh degree=2| :   8%|▉          | 2498/30000 [01:36<11:40, 39.23it/s]Step 2500: 2933 GSs duplicated, 3860 GSs split. Now having 161150 GSs.\n",
      "Step 2500: 519 GSs pruned. Now having 160631 GSs.\n",
      "loss=0.168| sh degree=2| :   9%|▉          | 2595/30000 [01:39<13:23, 34.13it/s]Step 2600: 2975 GSs duplicated, 3674 GSs split. Now having 167280 GSs.\n",
      "Step 2600: 504 GSs pruned. Now having 166776 GSs.\n",
      "loss=0.155| sh degree=2| :   9%|▉          | 2700/30000 [01:42<12:06, 37.58it/s]Step 2700: 2869 GSs duplicated, 3718 GSs split. Now having 173363 GSs.\n",
      "Step 2700: 570 GSs pruned. Now having 172793 GSs.\n",
      "loss=0.152| sh degree=2| :   9%|█          | 2797/30000 [01:45<11:49, 38.32it/s]Step 2800: 3004 GSs duplicated, 3458 GSs split. Now having 179255 GSs.\n",
      "Step 2800: 530 GSs pruned. Now having 178725 GSs.\n",
      "loss=0.152| sh degree=2| :  10%|▊        | 2897/30000 [01:56<1:53:32,  3.98it/s]Step 2900: 2975 GSs duplicated, 3456 GSs split. Now having 185156 GSs.\n",
      "Step 2900: 589 GSs pruned. Now having 184567 GSs.\n",
      "loss=0.169| sh degree=3| :  10%|█          | 2999/30000 [02:10<24:38, 18.26it/s]Step 3000: 3242 GSs duplicated, 3460 GSs split. Now having 191269 GSs.\n",
      "Step 3000: 564 GSs pruned. Now having 190705 GSs.\n",
      "loss=0.149| sh degree=3| :  10%|█▏         | 3097/30000 [02:14<10:35, 42.35it/s]Step 3100: 190 GSs duplicated, 1756 GSs split. Now having 192651 GSs.\n",
      "Step 3100: 50760 GSs pruned. Now having 141891 GSs.\n",
      "loss=0.208| sh degree=3| :  11%|█▏         | 3198/30000 [02:16<11:06, 40.23it/s]Step 3200: 1196 GSs duplicated, 4761 GSs split. Now having 147848 GSs.\n",
      "Step 3200: 2997 GSs pruned. Now having 144851 GSs.\n",
      "loss=0.145| sh degree=3| :  11%|█▏         | 3295/30000 [02:19<08:58, 49.63it/s]Step 3300: 2107 GSs duplicated, 5281 GSs split. Now having 152239 GSs.\n",
      "Step 3300: 1955 GSs pruned. Now having 150284 GSs.\n",
      "loss=0.175| sh degree=3| :  11%|█▏         | 3400/30000 [02:22<10:53, 40.72it/s]Step 3400: 2587 GSs duplicated, 5505 GSs split. Now having 158376 GSs.\n",
      "Step 3400: 1826 GSs pruned. Now having 156550 GSs.\n",
      "loss=0.176| sh degree=3| :  12%|█▎         | 3495/30000 [02:26<15:48, 27.94it/s]Step 3500: 3056 GSs duplicated, 5165 GSs split. Now having 164771 GSs.\n",
      "Step 3500: 1764 GSs pruned. Now having 163007 GSs.\n",
      "loss=0.158| sh degree=3| :  12%|█▎         | 3596/30000 [02:30<35:02, 12.56it/s]Step 3600: 3317 GSs duplicated, 4989 GSs split. Now having 171313 GSs.\n",
      "Step 3600: 1721 GSs pruned. Now having 169592 GSs.\n",
      "loss=0.146| sh degree=3| :  12%|█▎         | 3699/30000 [02:37<16:47, 26.11it/s]Step 3700: 3558 GSs duplicated, 4684 GSs split. Now having 177834 GSs.\n",
      "Step 3700: 1546 GSs pruned. Now having 176288 GSs.\n",
      "loss=0.159| sh degree=3| :  13%|█▍         | 3798/30000 [02:41<14:11, 30.76it/s]Step 3800: 3868 GSs duplicated, 4413 GSs split. Now having 184569 GSs.\n",
      "Step 3800: 1614 GSs pruned. Now having 182955 GSs.\n",
      "loss=0.161| sh degree=3| :  13%|█▍         | 3897/30000 [02:44<12:26, 34.96it/s]Step 3900: 3938 GSs duplicated, 4150 GSs split. Now having 191043 GSs.\n",
      "Step 3900: 1519 GSs pruned. Now having 189524 GSs.\n",
      "loss=0.167| sh degree=3| :  13%|█▍         | 3998/30000 [02:47<11:52, 36.50it/s]Step 4000: 4087 GSs duplicated, 4044 GSs split. Now having 197655 GSs.\n",
      "Step 4000: 1525 GSs pruned. Now having 196130 GSs.\n",
      "loss=0.174| sh degree=3| :  14%|█▌         | 4097/30000 [02:50<12:29, 34.56it/s]Step 4100: 4016 GSs duplicated, 3996 GSs split. Now having 204142 GSs.\n",
      "Step 4100: 1412 GSs pruned. Now having 202730 GSs.\n",
      "loss=0.172| sh degree=3| :  14%|█▌         | 4199/30000 [02:53<16:41, 25.75it/s]Step 4200: 4569 GSs duplicated, 4127 GSs split. Now having 211426 GSs.\n",
      "Step 4200: 1448 GSs pruned. Now having 209978 GSs.\n",
      "loss=0.174| sh degree=3| :  14%|█▌         | 4300/30000 [02:57<14:31, 29.51it/s]Step 4300: 4358 GSs duplicated, 3751 GSs split. Now having 218087 GSs.\n",
      "Step 4300: 1370 GSs pruned. Now having 216717 GSs.\n",
      "loss=0.172| sh degree=3| :  15%|█▌         | 4400/30000 [03:01<15:22, 27.75it/s]Step 4400: 4317 GSs duplicated, 3586 GSs split. Now having 224620 GSs.\n",
      "Step 4400: 1350 GSs pruned. Now having 223270 GSs.\n",
      "loss=0.156| sh degree=3| :  15%|█▋         | 4500/30000 [03:04<15:38, 27.17it/s]Step 4500: 4450 GSs duplicated, 3757 GSs split. Now having 231477 GSs.\n",
      "Step 4500: 1447 GSs pruned. Now having 230030 GSs.\n",
      "loss=0.141| sh degree=3| :  15%|█▋         | 4600/30000 [03:08<15:32, 27.25it/s]Step 4600: 4221 GSs duplicated, 3431 GSs split. Now having 237682 GSs.\n",
      "Step 4600: 1404 GSs pruned. Now having 236278 GSs.\n",
      "loss=0.161| sh degree=3| :  16%|█▋         | 4697/30000 [03:11<13:52, 30.38it/s]Step 4700: 4645 GSs duplicated, 3489 GSs split. Now having 244412 GSs.\n",
      "Step 4700: 1361 GSs pruned. Now having 243051 GSs.\n",
      "loss=0.150| sh degree=3| :  16%|█▊         | 4797/30000 [03:15<14:27, 29.06it/s]Step 4800: 4606 GSs duplicated, 3477 GSs split. Now having 251134 GSs.\n",
      "Step 4800: 1420 GSs pruned. Now having 249714 GSs.\n",
      "loss=0.152| sh degree=3| :  16%|█▊         | 4898/30000 [03:18<14:52, 28.12it/s]Step 4900: 4602 GSs duplicated, 3438 GSs split. Now having 257754 GSs.\n",
      "Step 4900: 1292 GSs pruned. Now having 256462 GSs.\n",
      "loss=0.168| sh degree=3| :  17%|█▊         | 4999/30000 [03:22<15:00, 27.75it/s]Step 5000: 4492 GSs duplicated, 3418 GSs split. Now having 264372 GSs.\n",
      "Step 5000: 1234 GSs pruned. Now having 263138 GSs.\n",
      "loss=0.141| sh degree=3| :  17%|█▊         | 5098/30000 [03:26<15:32, 26.71it/s]Step 5100: 4699 GSs duplicated, 3630 GSs split. Now having 271467 GSs.\n",
      "Step 5100: 1249 GSs pruned. Now having 270218 GSs.\n",
      "loss=0.176| sh degree=3| :  17%|█▉         | 5200/30000 [03:29<14:33, 28.39it/s]Step 5200: 4654 GSs duplicated, 3448 GSs split. Now having 278320 GSs.\n",
      "Step 5200: 1265 GSs pruned. Now having 277055 GSs.\n",
      "loss=0.174| sh degree=3| :  18%|█▉         | 5300/30000 [03:33<14:37, 28.16it/s]Step 5300: 4653 GSs duplicated, 3406 GSs split. Now having 285114 GSs.\n",
      "Step 5300: 1232 GSs pruned. Now having 283882 GSs.\n",
      "loss=0.155| sh degree=3| :  18%|█▉         | 5400/30000 [03:37<14:29, 28.30it/s]Step 5400: 4876 GSs duplicated, 3607 GSs split. Now having 292365 GSs.\n",
      "Step 5400: 1282 GSs pruned. Now having 291083 GSs.\n",
      "loss=0.156| sh degree=3| :  18%|██         | 5498/30000 [03:40<15:28, 26.39it/s]Step 5500: 4530 GSs duplicated, 3348 GSs split. Now having 298961 GSs.\n",
      "Step 5500: 1133 GSs pruned. Now having 297828 GSs.\n",
      "loss=0.154| sh degree=3| :  19%|██         | 5599/30000 [03:44<15:00, 27.10it/s]Step 5600: 5279 GSs duplicated, 3611 GSs split. Now having 306718 GSs.\n",
      "Step 5600: 1202 GSs pruned. Now having 305516 GSs.\n",
      "loss=0.173| sh degree=3| :  19%|██         | 5700/30000 [03:48<14:11, 28.55it/s]Step 5700: 5029 GSs duplicated, 3479 GSs split. Now having 314024 GSs.\n",
      "Step 5700: 1202 GSs pruned. Now having 312822 GSs.\n",
      "loss=0.136| sh degree=3| :  19%|██▏        | 5797/30000 [03:52<16:35, 24.32it/s]Step 5800: 5045 GSs duplicated, 3339 GSs split. Now having 321206 GSs.\n",
      "Step 5800: 1234 GSs pruned. Now having 319972 GSs.\n",
      "loss=0.152| sh degree=3| :  20%|██▏        | 5899/30000 [03:55<14:14, 28.19it/s]Step 5900: 5411 GSs duplicated, 3534 GSs split. Now having 328917 GSs.\n",
      "Step 5900: 1271 GSs pruned. Now having 327646 GSs.\n",
      "loss=0.154| sh degree=3| :  20%|██▏        | 5998/30000 [03:59<15:55, 25.11it/s]Step 6000: 5009 GSs duplicated, 3375 GSs split. Now having 336030 GSs.\n",
      "Step 6000: 1278 GSs pruned. Now having 334752 GSs.\n",
      "loss=0.163| sh degree=3| :  20%|██▏        | 6099/30000 [04:03<15:42, 25.36it/s]Step 6100: 310 GSs duplicated, 2683 GSs split. Now having 337745 GSs.\n",
      "Step 6100: 62725 GSs pruned. Now having 275020 GSs.\n",
      "loss=0.156| sh degree=3| :  21%|██▎        | 6198/30000 [04:07<15:12, 26.08it/s]Step 6200: 1652 GSs duplicated, 4789 GSs split. Now having 281461 GSs.\n",
      "Step 6200: 2212 GSs pruned. Now having 279249 GSs.\n",
      "loss=0.136| sh degree=3| :  21%|█▉       | 6298/30000 [04:17<1:14:26,  5.31it/s]Step 6300: 2806 GSs duplicated, 5011 GSs split. Now having 287066 GSs.\n",
      "Step 6300: 1587 GSs pruned. Now having 285479 GSs.\n",
      "loss=0.144| sh degree=3| :  21%|██▎        | 6400/30000 [04:22<11:10, 35.18it/s]Step 6400: 3233 GSs duplicated, 4681 GSs split. Now having 293393 GSs.\n",
      "Step 6400: 1432 GSs pruned. Now having 291961 GSs.\n",
      "loss=0.151| sh degree=3| :  22%|██▍        | 6499/30000 [04:27<19:14, 20.36it/s]Step 6500: 4151 GSs duplicated, 4672 GSs split. Now having 300784 GSs.\n",
      "Step 6500: 1216 GSs pruned. Now having 299568 GSs.\n",
      "loss=0.170| sh degree=3| :  22%|██▍        | 6597/30000 [04:30<12:27, 31.30it/s]Step 6600: 4179 GSs duplicated, 4454 GSs split. Now having 308201 GSs.\n",
      "Step 6600: 1180 GSs pruned. Now having 307021 GSs.\n",
      "loss=0.137| sh degree=3| :  22%|██▍        | 6681/30000 [04:33<13:07, 29.61it/s]^C\n",
      "loss=0.137| sh degree=3| :  22%|██▍        | 6683/30000 [04:33<15:53, 24.46it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/junzhe/Projects/gsplat/examples/rgbd_trainer.py\", line 778, in <module>\n",
      "    main(cfg)\n",
      "  File \"/home/junzhe/Projects/gsplat/examples/rgbd_trainer.py\", line 768, in main\n",
      "    runner.train()\n",
      "  File \"/home/junzhe/Projects/gsplat/examples/rgbd_trainer.py\", line 516, in train\n",
      "    desc = f\"loss={loss.item():.3f}| \" f\"sh degree={sh_degree_to_use}| \"\n",
      "KeyboardInterrupt\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python rgbd_trainer.py \\\n",
    "    --data-dir /run/media/junzhe/SLAM_DATA/data/museum/kitchen_rgbd_pcd/ \\\n",
    "    --data-factor 1 \\\n",
    "    --result-dir /run/media/junzhe/SLAM_DATA/data/museum/gsplat/kitchen_rgbd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python rgbd_trainer.py \\\n",
    "    --data-dir /run/media/junzhe/SLAM_DATA/data/museum/kitchen_rgbd_pcd/ \\\n",
    "    --data-factor 1 \\\n",
    "    --result-dir /run/media/junzhe/SLAM_DATA/data/museum/gsplat/kitchen_rgbd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1musage\u001b[0m: rgbd_trainer.py [-h] [OPTIONS]\n",
      "\n",
      "\u001b[2m╭─\u001b[0m\u001b[2m options \u001b[0m\u001b[2m─────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "\u001b[2m│\u001b[0m -h, --help              \u001b[2mshow this help message and exit\u001b[0m                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --disable-viewer, --no-disable-viewer                                      \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mDisable viewer\u001b[0m \u001b[36m(default: False)\u001b[0m                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --ckpt \u001b[1m{None}|STR\u001b[0m       \u001b[2mPath to the .pt file. If provide, it will skip \u001b[0m    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mtraining and render a video\u001b[0m \u001b[36m(default: None)\u001b[0m        \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --data-dir \u001b[1mSTR\u001b[0m          \u001b[2mrgb/ depth/ traj.tum\u001b[0m \u001b[36m(default: \u001b[0m                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36m/run/media/junzhe/SLAM_DATA/data/museum/colmap/ki…\u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --data-factor \u001b[1mINT\u001b[0m       \u001b[2mDownsample factor for the dataset\u001b[0m \u001b[36m(default: 4)\u001b[0m     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --result-dir \u001b[1mSTR\u001b[0m        \u001b[2mDirectory to save results\u001b[0m \u001b[36m(default: \u001b[0m               \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36m/run/media/junzhe/SLAM_DATA/data/gsplat/)\u001b[0m          \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --test-every \u001b[1mINT\u001b[0m        \u001b[2mEvery N images there is a test image\u001b[0m \u001b[36m(default: 10)\u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --patch-size \u001b[1m{None}|INT\u001b[0m                                                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mRandom crop size for training  (experimental)\u001b[0m      \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36m(default: None)\u001b[0m                                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --global-scale \u001b[1mFLOAT\u001b[0m    \u001b[2mA global scaler that applies to the scene size \u001b[0m    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mrelated parameters\u001b[0m \u001b[36m(default: 1.0)\u001b[0m                  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --port \u001b[1mINT\u001b[0m              \u001b[2mPort for the viewer server\u001b[0m \u001b[36m(default: 8080)\u001b[0m         \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --batch-size \u001b[1mINT\u001b[0m        \u001b[2mBatch size for training. Learning rates are scaled\u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mautomatically\u001b[0m \u001b[36m(default: 1)\u001b[0m                         \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --steps-scaler \u001b[1mFLOAT\u001b[0m    \u001b[2mA global factor to scale the number of training \u001b[0m   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2msteps\u001b[0m \u001b[36m(default: 1.0)\u001b[0m                               \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --max-steps \u001b[1mINT\u001b[0m         \u001b[2mNumber of training steps\u001b[0m \u001b[36m(default: 30000)\u001b[0m          \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --eval-steps \u001b[1m[INT [INT ...]]\u001b[0m                                               \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mSteps to evaluate the model\u001b[0m \u001b[36m(default: 7000 30000)\u001b[0m  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --save-steps \u001b[1m[INT [INT ...]]\u001b[0m                                               \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mSteps to save the model\u001b[0m \u001b[36m(default: 7000 30000)\u001b[0m      \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --init-type \u001b[1mSTR\u001b[0m         \u001b[2mInitialization strategy\u001b[0m \u001b[36m(default: sfm)\u001b[0m             \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --init-num-pts \u001b[1mINT\u001b[0m      \u001b[2mInitial number of GSs. Ignored if using sfm\u001b[0m        \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36m(default: 100000)\u001b[0m                                  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --init-extent \u001b[1mFLOAT\u001b[0m     \u001b[2mInitial extent of GSs as a multiple of the camera \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mextent. Ignored if using sfm\u001b[0m \u001b[36m(default: 3.0)\u001b[0m        \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --sh-degree \u001b[1mINT\u001b[0m         \u001b[2mDegree of spherical harmonics\u001b[0m \u001b[36m(default: 3)\u001b[0m         \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --sh-degree-interval \u001b[1mINT\u001b[0m                                                   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mTurn on another SH degree every this steps\u001b[0m         \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36m(default: 1000)\u001b[0m                                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --init-opa \u001b[1mFLOAT\u001b[0m        \u001b[2mInitial opacity of GS\u001b[0m \u001b[36m(default: 0.1)\u001b[0m               \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --init-scale \u001b[1mFLOAT\u001b[0m      \u001b[2mInitial scale of GS\u001b[0m \u001b[36m(default: 1.0)\u001b[0m                 \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --ssim-lambda \u001b[1mFLOAT\u001b[0m     \u001b[2mWeight for SSIM loss\u001b[0m \u001b[36m(default: 0.2)\u001b[0m                \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --near-plane \u001b[1mFLOAT\u001b[0m      \u001b[2mNear plane clipping distance\u001b[0m \u001b[36m(default: 0.01)\u001b[0m       \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --far-plane \u001b[1mFLOAT\u001b[0m       \u001b[2mFar plane clipping distance\u001b[0m \u001b[36m(default: \u001b[0m             \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36m10000000000.0)\u001b[0m                                     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --prune-opa \u001b[1mFLOAT\u001b[0m       \u001b[2mGSs with opacity below this value will be pruned\u001b[0m   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36m(default: 0.005)\u001b[0m                                   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --grow-grad2d \u001b[1mFLOAT\u001b[0m     \u001b[2mGSs with image plane gradient above this value \u001b[0m    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mwill be split/duplicated\u001b[0m \u001b[36m(default: 0.0002)\u001b[0m         \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --grow-scale3d \u001b[1mFLOAT\u001b[0m    \u001b[2mGSs with scale below this value will be \u001b[0m           \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mduplicated. Above will be split\u001b[0m \u001b[36m(default: 0.01)\u001b[0m    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --prune-scale3d \u001b[1mFLOAT\u001b[0m   \u001b[2mGSs with scale above this value will be pruned.\u001b[0m    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36m(default: 0.1)\u001b[0m                                     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --refine-start-iter \u001b[1mINT\u001b[0m                                                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mStart refining GSs after this iteration\u001b[0m \u001b[36m(default: \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36m500)\u001b[0m                                               \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --refine-stop-iter \u001b[1mINT\u001b[0m  \u001b[2mStop refining GSs after this iteration\u001b[0m \u001b[36m(default: \u001b[0m  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36m15000)\u001b[0m                                             \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --reset-every \u001b[1mINT\u001b[0m       \u001b[2mReset opacities every this steps\u001b[0m \u001b[36m(default: 3000)\u001b[0m   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --refine-every \u001b[1mINT\u001b[0m      \u001b[2mRefine GSs every this steps\u001b[0m \u001b[36m(default: 100)\u001b[0m         \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --packed, --no-packed   \u001b[2mUse packed mode for rasterization, this leads to \u001b[0m  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mless memory usage but slightly slower.\u001b[0m \u001b[36m(default: \u001b[0m  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36mFalse)\u001b[0m                                             \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --sparse-grad, --no-sparse-grad                                            \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mUse sparse gradients for optimization. \u001b[0m            \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2m(experimental)\u001b[0m \u001b[36m(default: False)\u001b[0m                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --absgrad, --no-absgrad                                                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mUse absolute gradient for pruning. This typically \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mrequires larger --grow_grad2d, e.g., 0.0008 or \u001b[0m    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2m0.0006\u001b[0m \u001b[36m(default: False)\u001b[0m                            \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --antialiased, --no-antialiased                                            \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mAnti-aliasing in rasterization. Might slightly \u001b[0m    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mhurt quantitative metrics.\u001b[0m \u001b[36m(default: False)\u001b[0m        \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --revised-opacity, --no-revised-opacity                                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mWhether to use revised opacity heuristic from \u001b[0m     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2marXiv:2404.06109 (experimental)\u001b[0m \u001b[36m(default: False)\u001b[0m   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --random-bkgd, --no-random-bkgd                                            \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mUse random background for training to discourage \u001b[0m  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mtransparency\u001b[0m \u001b[36m(default: False)\u001b[0m                      \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --pose-opt, --no-pose-opt                                                  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mEnable camera optimization.\u001b[0m \u001b[36m(default: False)\u001b[0m       \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --pose-opt-lr \u001b[1mFLOAT\u001b[0m     \u001b[2mLearning rate for camera optimization\u001b[0m \u001b[36m(default: \u001b[0m   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36m1e-05)\u001b[0m                                             \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --pose-opt-reg \u001b[1mFLOAT\u001b[0m    \u001b[2mRegularization for camera optimization as weight \u001b[0m  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mdecay\u001b[0m \u001b[36m(default: 1e-06)\u001b[0m                             \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --pose-noise \u001b[1mFLOAT\u001b[0m      \u001b[2mAdd noise to camera extrinsics. This is only to \u001b[0m   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mtest the camera pose optimization.\u001b[0m \u001b[36m(default: 0.0)\u001b[0m  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --app-opt, --no-app-opt                                                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mEnable appearance optimization. (experimental)\u001b[0m     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36m(default: False)\u001b[0m                                   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --app-embed-dim \u001b[1mINT\u001b[0m     \u001b[2mAppearance embedding dimension\u001b[0m \u001b[36m(default: 16)\u001b[0m       \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --app-opt-lr \u001b[1mFLOAT\u001b[0m      \u001b[2mLearning rate for appearance optimization\u001b[0m          \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36m(default: 0.001)\u001b[0m                                   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --app-opt-reg \u001b[1mFLOAT\u001b[0m     \u001b[2mRegularization for appearance optimization as \u001b[0m     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mweight decay\u001b[0m \u001b[36m(default: 1e-06)\u001b[0m                      \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --depth-loss, --no-depth-loss                                              \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mEnable depth loss. (experimental)\u001b[0m \u001b[36m(default: False)\u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --depth-lambda \u001b[1mFLOAT\u001b[0m    \u001b[2mWeight for depth loss\u001b[0m \u001b[36m(default: 0.05)\u001b[0m              \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --tb-every \u001b[1mINT\u001b[0m          \u001b[2mDump information to tensorboard every this steps\u001b[0m   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36m(default: 100)\u001b[0m                                     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m --tb-save-image, --no-tb-save-image                                        \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[2mSave training images to tensorboard\u001b[0m \u001b[36m(default: \u001b[0m     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                         \u001b[36mFalse)\u001b[0m                                             \u001b[2m│\u001b[0m\n",
      "\u001b[2m╰────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python rgbd_trainer.py --help"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
